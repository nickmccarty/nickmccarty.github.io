<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Building a GeoTIFF Object Detection Web App | Nick McCarty</title>
  <meta name="description" content="A web application for running Faster R-CNN on aerial imagery with real-time progress and georeferenced output.">
  <link rel="icon" type="image/png" sizes="32x32" href="../assets/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../assets/images/favicon-16x16.png">
  <link rel="stylesheet" href="../assets/css/styles.css">
  <script src="../assets/js/color-modes.js"></script>
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-YT69KZ91W7"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-YT69KZ91W7');
  </script>
</head>
<body>
  <nav>
    <a href="../" class="logo" aria-label="Home"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16"><path d="M8.354 1.146a.5.5 0 0 0-.708 0l-6 6A.5.5 0 0 0 1.5 7.5v7a.5.5 0 0 0 .5.5h4.5a.5.5 0 0 0 .5-.5v-4h2v4a.5.5 0 0 0 .5.5H14a.5.5 0 0 0 .5-.5v-7a.5.5 0 0 0-.146-.354L13 5.793V2.5a.5.5 0 0 0-.5-.5h-1a.5.5 0 0 0-.5.5v1.293zM2.5 14V7.707l5.5-5.5 5.5 5.5V14H10v-4a.5.5 0 0 0-.5-.5h-3a.5.5 0 0 0-.5.5v4z"/></svg></a>
    <div class="nav-right">
      <div class="nav-links">
        <a href="../about.html">About</a>
        <a href="../blog.html" class="active">Blog</a>
        <a href="../contact.html">Contact</a>
      </div>
      <button class="theme-toggle" aria-label="Toggle theme">
        <svg class="sun-icon" xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
          <path d="M8 11a3 3 0 1 1 0-6 3 3 0 0 1 0 6m0 1a4 4 0 1 0 0-8 4 4 0 0 0 0 8M8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0m0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13m8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5M3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8m10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0m-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0m9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707M4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708"/>
        </svg>
        <svg class="moon-icon" xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
          <path d="M6 .278a.77.77 0 0 1 .08.858 7.2 7.2 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277q.792-.001 1.533-.16a.79.79 0 0 1 .81.316.73.73 0 0 1-.031.893A8.35 8.35 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.75.75 0 0 1 6 .278M4.858 1.311A7.27 7.27 0 0 0 1.025 7.71c0 4.02 3.279 7.276 7.319 7.276a7.32 7.32 0 0 0 5.205-2.162q-.506.063-1.029.063c-4.61 0-8.343-3.714-8.343-8.29 0-1.167.242-2.278.681-3.286"/>
          <path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.73 1.73 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.73 1.73 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.73 1.73 0 0 0 1.097-1.097zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.16 1.16 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.16 1.16 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732z"/>
        </svg>
      </button>
    </div>
  </nav>

  <main>
    <a href="../blog.html" class="back-link">&larr; Back to Blog</a>

    <article>
      <h1>Building a GeoTIFF Object Detection Web App</h1>
      <div class="post-meta">December 28, 2025 &bull; 5 min read</div>

      <!-- TOPIC + MOTIVATION + CONTRIBUTION -->
      <p>
        Running object detection on drone or satellite imagery means working with files that can exceed
        10,000 pixels per side&mdash;too large to load into GPU memory at once. Standard workflows
        require command-line scripting, manual coordinate system conversions, and offer no feedback
        during inference that can take minutes per image. This project wraps a trained Faster R-CNN
        model in a browser interface that handles tiled inference, automatic <span class="glossary-term" data-term="crs">CRS</span> reprojection, real-time
        progress updates, and interactive false positive removal&mdash;making the full pipeline
        accessible without touching a terminal.
      </p>

      <!-- DETAIL/NUANCE -->
      <h2>Tiled Inference and Progress Streaming</h2>

      <p>
        The core challenge is processing images that don't fit in memory. The solution is tile-based
        inference: slice the image into 1024px patches with 128px overlap, run detection on each tile,
        then merge results. The overlap prevents objects at tile boundaries from being clipped. Each
        detection's bounding box gets transformed from pixel coordinates back to the original CRS using
        the GeoTIFF's <span class="glossary-term" data-term="affine-transform">affine transform</span>, preserving georeferencing throughout.
      </p>

      <p>
        For user experience, HTTP request-response doesn't work&mdash;inference on a large image can
        process hundreds of tiles. Instead, the client opens a <span class="glossary-term" data-term="websocket">WebSocket</span> connection and the server
        streams progress as each tile completes. The implementation detail that matters: PyTorch
        inference blocks Python's event loop, so inference runs in a thread pool executor while
        <code>asyncio.run_coroutine_threadsafe</code> pushes progress updates back to the WebSocket
        from the worker thread. This keeps the server responsive during long-running jobs.
      </p>

      <!-- EVIDENCE / SECONDARY CONTRIBUTIONS -->
      <h2>Coordinate Systems and Post-Processing</h2>

      <p>
        GeoTIFFs arrive in arbitrary projections&mdash;UTM zones, state plane, Web Mercator. Leaflet
        expects <span class="glossary-term" data-term="wgs84">WGS84</span>. Rather than require users to reproject before upload, the app generates a
        high-resolution overlay reprojected to EPSG:4326 using rasterio's <code>reproject</code> with
        <span class="glossary-term" data-term="lanczos">Lanczos resampling</span>. Detection coordinates convert to WGS84 for display but the exported <span class="glossary-term" data-term="geojson">GeoJSON</span>
        preserves the original CRS for downstream GIS workflows.
      </p>

      <p>
        Two post-processing steps clean up results. First, automatic geometry merging: tile-based
        inference often produces duplicate detections for objects spanning boundaries, so a
        buffer-union-unbuffer operation consolidates overlapping boxes. Second, interactive editing:
        users click detection polygons to select them (they turn red), then delete to remove false
        positives. Deletions only affect the export&mdash;the original detections remain visible
        for comparison.
      </p>

      <!-- LIMITATIONS -->
      <h2>Limitations</h2>

      <p>
        The model loads into memory at startup and stays resident. For single-user local deployment
        that's fine; for shared infrastructure, lazy loading or a separate inference service would
        scale better. Tile size and overlap are hardcoded at 1024px and 128px&mdash;making these
        configurable would let users optimize for their imagery characteristics and object sizes.
        The frontend handles one file at a time; batch upload support would streamline processing
        multiple GeoTIFFs without repeated uploads.
      </p>

      <!-- IMPACT: NARROW + BROAD -->
      <h2>Takeaways</h2>

      <p>
        For geospatial machine learning, the infrastructure around inference&mdash;handling large files,
        preserving coordinate systems, providing progress feedback, enabling result correction&mdash;often
        requires more code than the model wrapper itself.
      </p>

      <p>
        More broadly: deploying ML is less about the model and more about the surrounding experience.
        A trained network is inert until it's embedded in a workflow where users can get data in,
        understand what's happening, and act on results. That plumbing is where most of the work lives.
      </p>

      <p>
        The code is available on <a href="https://github.com/nickmccarty" target="_blank" rel="noopener">GitHub</a>.
      </p>

      <div class="related-post">
        <span class="related-label">Related</span>
        <a href="./training-faster-rcnn-geospatial.html">
          <h4>Training Faster R-CNN for Geospatial Object Detection</h4>
          <p>How the model powering this app was trained&mdash;from SAM masks to production detector.</p>
          <span class="read-more">Read more &rarr;</span>
        </a>
      </div>
    </article>
  </main>

  <!-- Glossary Modal -->
  <div class="modal-overlay glossary-modal" id="glossary-modal">
    <div class="modal">
      <div class="modal-header">
        <h3 id="glossary-term-title"></h3>
        <button class="modal-close" aria-label="Close">&times;</button>
      </div>
      <div class="modal-body">
        <p id="glossary-term-definition"></p>
        <p class="context-note" id="glossary-term-context"></p>
      </div>
    </div>
  </div>

  <script>
    // Glossary term definitions
    const glossaryTerms = {
      'crs': {
        title: 'CRS (Coordinate Reference System)',
        definition: 'A system that defines how geographic coordinates map to locations on Earth. Different CRS use different projections, datums, and units—UTM uses meters in zones, WGS84 uses degrees globally. Mismatched CRS cause features to appear in wrong locations.',
        context: 'Drone imagery arrives in various CRS (UTM zones, state plane). The app automatically reprojects to WGS84 for web display while preserving the original CRS in exports for GIS compatibility.'
      },
      'affine-transform': {
        title: 'Affine Transform',
        definition: 'A mathematical transformation that converts between pixel coordinates (row, column) and geographic coordinates (x, y). For GeoTIFFs, it\'s a 6-parameter matrix encoding origin, pixel size, and rotation.',
        context: 'When detection runs on image tiles, results are in pixel coordinates. The affine transform converts bounding boxes back to real-world coordinates, enabling GPS-accurate export of detection locations.'
      },
      'websocket': {
        title: 'WebSocket',
        definition: 'A protocol enabling persistent, bidirectional communication between browser and server. Unlike HTTP\'s request-response pattern, WebSockets keep a connection open for real-time data streaming in both directions.',
        context: 'Processing hundreds of tiles takes minutes. WebSockets let the server push progress updates as each tile completes, giving users real-time feedback instead of waiting for a single final response.'
      },
      'wgs84': {
        title: 'WGS84',
        definition: 'World Geodetic System 1984—the global standard coordinate reference system used by GPS. Coordinates are latitude/longitude in degrees. EPSG code 4326. Most web mapping libraries (Leaflet, Google Maps) expect WGS84.',
        context: 'Leaflet needs WGS84 coordinates to display detections on the map. We reproject imagery and detection boxes to WGS84 for display, but preserve original coordinates in exports for precision.'
      },
      'lanczos': {
        title: 'Lanczos Resampling',
        definition: 'A high-quality interpolation algorithm for resizing or reprojecting images. It uses a windowed sinc function to preserve sharp edges and fine details better than simpler methods like bilinear or nearest-neighbor.',
        context: 'When reprojecting GeoTIFFs to WGS84, Lanczos resampling maintains image quality—important for aerial imagery where small objects (pots) need to remain visually distinct after transformation.'
      },
      'geojson': {
        title: 'GeoJSON',
        definition: 'A JSON-based format for encoding geographic features (points, lines, polygons) with their properties. Widely supported by GIS software, web mapping libraries, and geospatial databases.',
        context: 'Detection results export as GeoJSON with each pot as a polygon feature. This integrates directly with QGIS, PostGIS, or other tools for further analysis, filtering, or visualization.'
      }
    };

    // Modal functionality
    const modal = document.getElementById('glossary-modal');
    const titleEl = document.getElementById('glossary-term-title');
    const definitionEl = document.getElementById('glossary-term-definition');
    const contextEl = document.getElementById('glossary-term-context');
    const closeBtn = modal.querySelector('.modal-close');

    // Open modal on term click
    document.querySelectorAll('.glossary-term').forEach(term => {
      term.addEventListener('click', () => {
        const termId = term.dataset.term;
        const termData = glossaryTerms[termId];

        if (termData) {
          titleEl.textContent = termData.title;
          definitionEl.textContent = termData.definition;
          contextEl.textContent = termData.context;
          modal.classList.add('active');
        }
      });
    });

    // Close modal
    closeBtn.addEventListener('click', () => modal.classList.remove('active'));
    modal.addEventListener('click', (e) => {
      if (e.target === modal) modal.classList.remove('active');
    });
    document.addEventListener('keydown', (e) => {
      if (e.key === 'Escape') modal.classList.remove('active');
    });
  </script>

  <footer>
    <div class="social-links">
      <a href="https://linkedin.com/in/nicholasmccarty" target="_blank" rel="noopener" aria-label="LinkedIn">
        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
          <path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401m-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822 0-1.359.54-1.359 1.248 0 .694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225h2.4"/>
        </svg>
      </a>
      <a href="https://github.com/nickmccarty" target="_blank" rel="noopener" aria-label="GitHub">
        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
          <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8"/>
        </svg>
      </a>
      <a href="mailto:nick@upskilled.consulting" aria-label="Email">
        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
          <path d="M0 4a2 2 0 0 1 2-2h12a2 2 0 0 1 2 2v8a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2zm2-1a1 1 0 0 0-1 1v.217l7 4.2 7-4.2V4a1 1 0 0 0-1-1zm13 2.383-4.708 2.825L15 11.105zm-.034 6.876-5.64-3.471L8 9.583l-1.326-.795-5.64 3.47A1 1 0 0 0 2 13h12a1 1 0 0 0 .966-.741M1 11.105l4.708-2.897L1 5.383z"/>
        </svg>
      </a>
    </div>
    <p>&copy; 2025 Nick McCarty. All rights reserved.</p>
  </footer>
</body>
</html>
